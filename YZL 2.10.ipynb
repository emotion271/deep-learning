{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ngZ08NlbskIy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 13
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1177
        },
        "outputId": "b1f3ce7d-30a0-4562-c69c-cf4b367107d5"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorlayer\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorlayer as tl\n",
        "from tensorlayer.layers import set_keep\n",
        "\n",
        "def main_test_cnn_layer():\n",
        "    \"\"\"Reimplementation of the TensorFlow official MNIST CNN tutorials:\n",
        "    - https://www.tensorflow.org/versions/r0.8/tutorials/mnist/pros/index.html\n",
        "    - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/mnist/convolutional.py\n",
        "    More TensorFlow official CNN tutorials can be found here:\n",
        "    - tutorial_cifar10.py\n",
        "    - https://www.tensorflow.org/versions/master/tutorials/deep_cnn/index.html\n",
        "    - For simplified CNN layer see \"Convolutional layer (Simplified)\"\n",
        "      in read the docs website.\n",
        "    \"\"\"\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = \\\n",
        "                    tl.files.load_mnist_dataset(shape=(-1, 28, 28, 1))\n",
        "\n",
        "    X_train = np.asarray(X_train, dtype=np.float32)\n",
        "    y_train = np.asarray(y_train, dtype=np.int64)\n",
        "    X_val = np.asarray(X_val, dtype=np.float32)\n",
        "    y_val = np.asarray(y_val, dtype=np.int64)\n",
        "    X_test = np.asarray(X_test, dtype=np.float32)\n",
        "    y_test = np.asarray(y_test, dtype=np.int64)\n",
        "\n",
        "    print('X_train.shape', X_train.shape)\n",
        "    print('y_train.shape', y_train.shape)\n",
        "    print('X_val.shape', X_val.shape)\n",
        "    print('y_val.shape', y_val.shape)\n",
        "    print('X_test.shape', X_test.shape)\n",
        "    print('y_test.shape', y_test.shape)\n",
        "    print('X %s   y %s' % (X_test.dtype, y_test.dtype))\n",
        "\n",
        "    sess = tf.InteractiveSession()\n",
        "\n",
        "    # Define the batchsize at the begin, you can give the batchsize in x and y_\n",
        "    # rather than 'None', this can allow TensorFlow to apply some optimizations\n",
        "    # – especially for convolutional layers.\n",
        "    batch_size = 128\n",
        "\n",
        "    \n",
        "    #batch_size可以被设为None,但是设置为具体数字时tensorflow能够为此进行一定的性能优化\n",
        "    x = tf.placeholder(tf.float32, shape=[batch_size, 28, 28, 1])   # [batch_size, height, width, channels]\n",
        "    y_ = tf.placeholder(tf.int64, shape=[batch_size,])\n",
        "\n",
        "    network = tl.layers.InputLayer(x, name='input')\n",
        "    ## Professional conv API for tensorflow user\n",
        "    # network = tl.layers.Conv2dLayer(network,\n",
        "    #                     act = tf.nn.relu,\n",
        "    #                     shape = [5, 5, 1, 32],  # 32 features for each 5x5 patch\n",
        "    #                     strides=[1, 1, 1, 1],\n",
        "    #                     padding='SAME',\n",
        "    #                     name ='cnn1')     # output: (?, 28, 28, 32)\n",
        "    # network = tl.layers.PoolLayer(network,\n",
        "    #                     ksize=[1, 2, 2, 1],\n",
        "    #                     strides=[1, 2, 2, 1],\n",
        "    #                     padding='SAME',\n",
        "    #                     pool = tf.nn.max_pool,\n",
        "    #                     name ='pool1',)   # output: (?, 14, 14, 32)\n",
        "    # network = tl.layers.Conv2dLayer(network,\n",
        "    #                     act = tf.nn.relu,\n",
        "    #                     shape = [5, 5, 32, 64], # 64 features for each 5x5 patch\n",
        "    #                     strides=[1, 1, 1, 1],\n",
        "    #                     padding='SAME',\n",
        "    #                     name ='cnn2')     # output: (?, 14, 14, 64)\n",
        "    # network = tl.layers.PoolLayer(network,\n",
        "    #                     ksize=[1, 2, 2, 1],\n",
        "    #                     strides=[1, 2, 2, 1],\n",
        "    #                     padding='SAME',\n",
        "    #                     pool = tf.nn.max_pool,\n",
        "    #                     name ='pool2',)   # output: (?, 7, 7, 64)\n",
        "    ## Simplified conv API for beginner (the same with the above layers)\n",
        "    network = tl.layers.Conv2d(network, 32, (5, 5), (1, 1),\n",
        "            act=tf.nn.relu, padding='SAME', name='cnn1')\n",
        "    network = tl.layers.MaxPool2d(network, (2, 2), (2, 2),\n",
        "            padding='SAME', name='pool1')\n",
        "    network = tl.layers.Conv2d(network, 64, (5, 5), (1, 1),\n",
        "            act=tf.nn.relu, padding='SAME', name='cnn2')\n",
        "    network = tl.layers.MaxPool2d(network, (2, 2), (2, 2),\n",
        "            padding='SAME', name='pool2')\n",
        "    ## end of conv\n",
        "    #将二维的tensor转化为一维向量，为之后的全连接层做准备\n",
        "    network = tl.layers.FlattenLayer(network, name='flatten')\n",
        "    network = tl.layers.DropoutLayer(network, keep=0.5, name='drop1')\n",
        "    network = tl.layers.DenseLayer(network, 256, act=tf.nn.relu, name='relu1')\n",
        "    network = tl.layers.DropoutLayer(network, keep=0.5, name='drop2')\n",
        "    network = tl.layers.DenseLayer(network, 10, act=tf.identity, name='output')\n",
        "\n",
        "    y = network.outputs\n",
        "\n",
        "    #定义损失函数，这里将交叉熵设为损失函数（详见《深度学习》6.2.1）\n",
        "    cost = tl.cost.cross_entropy(y, y_, 'cost')\n",
        "\n",
        "    #返回表示预测值与真实值是否相等的一个bool向量，tf.argmax返回向量中最大值的坐标（在此例中即为预测的数字）\n",
        "    correct_prediction = tf.equal(tf.argmax(y, 1), y_)\n",
        "    #tf.reduce_mean()以取平均值的方式将tensor降维，选择给参数axis参数赋值可以选择从哪个维度进行运算，在此例中axis缺失，将tensor转化为一个一维标量\n",
        "    #tf.cast用于转化数据的type，在此例中将之前得出的bool向量转化为浮点数向量，取平均转化为一维标量之后即为预测的正确率\n",
        "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    # train\n",
        "    #迭代次数\n",
        "    n_epoch = 200\n",
        "    learning_rate = 0.0001\n",
        "    #每迭代十次打印一份信息\n",
        "    print_freq = 10\n",
        "\n",
        "    #获取所有layer中的参数\n",
        "    train_params = network.all_params\n",
        "    \n",
        "    #选择优化器\n",
        "    train_op = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999,\n",
        "        epsilon=1e-08, use_locking=False).minimize(cost, var_list=train_params)\n",
        "\n",
        "    #初始化所有变量\n",
        "    tl.layers.initialize_global_variables(sess)\n",
        "    \n",
        "    #输出参数和layer的信息\n",
        "    network.print_params()\n",
        "    network.print_layers()\n",
        "\n",
        "    print('   learning_rate: %f' % learning_rate)\n",
        "    print('   batch_size: %d' % batch_size)\n",
        "\n",
        "    \n",
        "    #进行迭代\n",
        "    for epoch in range(n_epoch):\n",
        "        start_time = time.time()\n",
        "        for X_train_a, y_train_a in tl.iterate.minibatches(\n",
        "                                    X_train, y_train, batch_size, shuffle=True):\n",
        "            feed_dict = {x: X_train_a, y_: y_train_a}\n",
        "            \n",
        "            #添加噪声层，.all_dorp为所有layer均有的属性，返回一个dict：{placeholder:float(噪声层的概率)}\n",
        "            feed_dict.update( network.all_drop )        # enable noise layers\n",
        "            #进行将数据加入神经网络中进行训练\n",
        "            sess.run(train_op, feed_dict=feed_dict)\n",
        "        #没迭代十次输出一次相关信息\n",
        "        if epoch + 1 == 1 or (epoch + 1) % print_freq == 0:\n",
        "            print(\"Epoch %d of %d took %fs\" % (epoch + 1, n_epoch, time.time() - start_time))\n",
        "            train_loss, train_acc, n_batch = 0, 0, 0\n",
        "            #随机获取一批测试数据\n",
        "            for X_train_a, y_train_a in tl.iterate.minibatches(\n",
        "                                    X_train, y_train, batch_size, shuffle=True):\n",
        "                #tl.utils.dict_to_one(),将值噪声层的概率改为1（预测时不需要dropout）\n",
        "                dp_dict = tl.utils.dict_to_one( network.all_drop )    # disable noise layers\n",
        "                feed_dict = {x: X_train_a, y_: y_train_a}\n",
        "                feed_dict.update(dp_dict)\n",
        "                #将参数放入sess中，获取损失函数和预测准确率的值\n",
        "                err, ac = sess.run([cost, acc], feed_dict=feed_dict)\n",
        "                train_loss += err; train_acc += ac; n_batch += 1\n",
        "            print(\"   train loss: %f\" % (train_loss/ n_batch))\n",
        "            print(\"   train acc: %f\" % (train_acc/ n_batch))\n",
        "            val_loss, val_acc, n_batch = 0, 0, 0\n",
        "            #在选出一批验证集并在验证集上做验证，关于数据的分割可以参考https://www.bilibili.com/video/av17204303/?from=search&seid=1804855494055998079#page=5\n",
        "            for X_val_a, y_val_a in tl.iterate.minibatches(\n",
        "                                        X_val, y_val, batch_size, shuffle=True):\n",
        "                dp_dict = tl.utils.dict_to_one( network.all_drop )    # disable noise layers\n",
        "                feed_dict = {x: X_val_a, y_: y_val_a}\n",
        "                feed_dict.update(dp_dict)\n",
        "                err, ac = sess.run([cost, acc], feed_dict=feed_dict)\n",
        "                val_loss += err; val_acc += ac; n_batch += 1\n",
        "            print(\"   val loss: %f\" % (val_loss/ n_batch))\n",
        "            print(\"   val acc: %f\" % (val_acc/ n_batch))\n",
        "            #将将卷积层以图片的形式输出\n",
        "            try:\n",
        "                tl.vis.CNN2d(network.all_params[0].eval(),\n",
        "                                    second=10, saveable=True,\n",
        "                                    name='cnn1_'+str(epoch+1), fig_idx=2012)\n",
        "            except:\n",
        "                print(\"You should change vis.CNN(), if you want to save the feature images for different dataset\")\n",
        "\n",
        "    print('Evaluation')\n",
        "    #输出模型的最终表现\n",
        "    test_loss, test_acc, n_batch = 0, 0, 0\n",
        "    for X_test_a, y_test_a in tl.iterate.minibatches(\n",
        "                                X_test, y_test, batch_size, shuffle=True):\n",
        "        dp_dict = tl.utils.dict_to_one( network.all_drop )    # disable noise layers\n",
        "        feed_dict = {x: X_test_a, y_: y_test_a}\n",
        "        feed_dict.update(dp_dict)\n",
        "        err, ac = sess.run([cost, acc], feed_dict=feed_dict)\n",
        "        test_loss += err; test_acc += ac; n_batch += 1\n",
        "    print(\"   test loss: %f\" % (test_loss/n_batch))\n",
        "    print(\"   test acc: %f\" % (test_acc/n_batch))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  #启动模型\n",
        "    sess = tf.InteractiveSession()\n",
        "    main_test_cnn_layer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorlayer\n",
            "  Using cached tensorlayer-1.7.4.zip\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from tensorlayer)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorlayer)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from tensorlayer)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tensorlayer)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorlayer)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorlayer)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorlayer)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorlayer)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorlayer)\n",
            "Requirement already satisfied: pillow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorlayer)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorlayer)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorlayer)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=2.1.0->scikit-image->tensorlayer)\n",
            "Requirement already satisfied: decorator>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image->tensorlayer)\n",
            "Building wheels for collected packages: tensorlayer\n",
            "  Running setup.py bdist_wheel for tensorlayer ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/40/81/7a/c5db8987981df637e7f66c8887228984778b45195fa50be72a\n",
            "Successfully built tensorlayer\n",
            "Installing collected packages: tensorlayer\n",
            "Successfully installed tensorlayer-1.7.4\n",
            "Load or Download MNIST > data/mnist\n",
            "data/mnist/train-images-idx3-ubyte.gz\n",
            "data/mnist/t10k-images-idx3-ubyte.gz\n",
            "X_train.shape (50000, 28, 28, 1)\n",
            "y_train.shape (50000,)\n",
            "X_val.shape (10000, 28, 28, 1)\n",
            "y_val.shape (10000,)\n",
            "X_test.shape (10000, 28, 28, 1)\n",
            "y_test.shape (10000,)\n",
            "X float32   y int64\n",
            "  [TL] InputLayer  input: (128, 28, 28, 1)\n",
            "  [TL] Conv2dLayer cnn1: shape:[5, 5, 1, 32] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
            "  [TL] PoolLayer   pool1: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
            "  [TL] Conv2dLayer cnn2: shape:[5, 5, 32, 64] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
            "  [TL] PoolLayer   pool2: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
            "  [TL] FlattenLayer flatten: 3136\n",
            "  [TL] DropoutLayer drop1: keep:0.500000 is_fix:False\n",
            "  [TL] DenseLayer  relu1: 256 relu\n",
            "  [TL] DropoutLayer drop2: keep:0.500000 is_fix:False\n",
            "  [TL] DenseLayer  output: 10 identity\n",
            "  param   0: cnn1/W_conv2d:0      (5, 5, 1, 32)      float32_ref (mean: -0.00020484853303059936, median: 0.00016805535415187478, std: 0.01706692762672901)   \n",
            "  param   1: cnn1/b_conv2d:0      (32,)              float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
            "  param   2: cnn2/W_conv2d:0      (5, 5, 32, 64)     float32_ref (mean: 0.00012685870751738548, median: 0.0001493248564656824, std: 0.017581690102815628)   \n",
            "  param   3: cnn2/b_conv2d:0      (64,)              float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
            "  param   4: relu1/W:0            (3136, 256)        float32_ref (mean: 1.3941624274593778e-05, median: -0.00012256234185770154, std: 0.08792487531900406)   \n",
            "  param   5: relu1/b:0            (256,)             float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
            "  param   6: output/W:0           (256, 10)          float32_ref (mean: -0.0007559508085250854, median: -0.0016242447309195995, std: 0.09018023312091827)   \n",
            "  param   7: output/b:0           (10,)              float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n",
            "  num of params: 857738\n",
            "  layer   0: cnn1/Relu:0          (128, 28, 28, 32)    float32\n",
            "  layer   1: pool1:0              (128, 14, 14, 32)    float32\n",
            "  layer   2: cnn2/Relu:0          (128, 14, 14, 64)    float32\n",
            "  layer   3: pool2:0              (128, 7, 7, 64)    float32\n",
            "  layer   4: flatten:0            (128, 3136)        float32\n",
            "  layer   5: drop1/mul:0          (128, 3136)        float32\n",
            "  layer   6: relu1/Relu:0         (128, 256)         float32\n",
            "  layer   7: drop2/mul:0          (128, 256)         float32\n",
            "  layer   8: output/Identity:0    (128, 10)          float32\n",
            "   learning_rate: 0.000100\n",
            "   batch_size: 128\n",
            "Epoch 1 of 200 took 125.400289s\n",
            "   train loss: 0.259058\n",
            "   train acc: 0.928726\n",
            "   val loss: 0.232839\n",
            "   val acc: 0.938001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PBVcdzGesomA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}